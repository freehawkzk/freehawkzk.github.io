# 【图像处理】-034 knn算法

&emsp;&emsp;在读matting文献的时候，读到了knn matting，该算法在抠图之后的效果还可以，在后面的深度抠图时常用语制作训练样本的mask。这里，先对knn进行简单介绍。

[TOC]

## 1 原理

&emsp;&emsp;knn算法，又称为k最近邻（k nearest neighbor）算法，是机器学习和数据挖掘中常用的一种分类算法。所谓K最近邻，是指K个最近的邻居的意思，说的是每个样本可以用最接近的K个邻居的属性来代表。

&emsp;&emsp;KNN算法的**核心思想**是，如果一个样本在特征中间中的K个最相邻的样本中的大多数属于某一个类别，那么这个样本也属于这个类别，并且具有这个类别上样本的特性。

&emsp;&emsp;该方法在确定分类决策上只依据最邻近的一个或者几个样本的类别来决定待分样本所属的类别。 
&emsp;&emsp;kNN方法在类别决策时，只与极少量的相邻样本有关。由于kNN方法主要靠周围有限的邻近的样本，而不是靠判别类域的方法来确定所属类别的，因此对于类域的交叉或重叠较多的待分样本集来说，kNN方法较其他方法更为适合。

## 2 优劣势

&emsp;&emsp;KNN算法适合于处理维度不高的数据，对于高维数据，由于每次计算时都需要遍历以往的样本计算距离，因此，计算量相当大。对于高维大数据量的处理不够便捷。

## 3 实现步骤

&emsp;&emsp;在训练集中数据和标签已知的情况下，输入测试数据，将测试数据的特征与训练集中对应的特征进行相互比较，找到训练集中与之最为相似的前K个数据，则该测试数据对应的类别就是K个数据中出现次数最多的那个分类，其算法的描述为：

- 1）计算测试数据与各个训练数据之间的距离；

- 2）按照距离的递增关系进行排序；

- 3）选取距离最小的K个点；

- 4）确定前K个点所在类别的出现频率；

- 5）返回前K个点中出现频率最高的类别作为测试数据的预测分类。
